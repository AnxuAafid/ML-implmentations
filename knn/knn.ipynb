{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\r\n",
    "    # vectorized version of computing all euclidean distances at once\r\n",
    "    # https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/Broadcasting.html\r\n",
    "    # https://stackoverflow.com/questions/27948363/numpy-broadcast-to-perform-euclidean-distance-vectorized\r\n",
    "    squared_dists = np.sum(x**2, axis=1)[:, np.newaxis] \\\r\n",
    "        + np.sum(y**2, axis=1) \\\r\n",
    "        - 2 * np.dot(x, y.T)\r\n",
    "    # clip very low negative values to 0 due to floating precisions\r\n",
    "    return np.sqrt(np.clip(squared_dists, a_min=0, a_max=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\r\n",
    "    def __init__(self, k=3):\r\n",
    "        self.k = k\r\n",
    "\r\n",
    "    def fit(self, X, y):\r\n",
    "        self.X_train = X\r\n",
    "        self.y_train = y\r\n",
    "\r\n",
    "    def predict(self, X):\r\n",
    "        # Compute distances between x and all examples in the training set\r\n",
    "        distances = euclidean_distance(X, self.X_train)\r\n",
    "        print(f\"{distances.shape = }\")\r\n",
    "        # Sort by distance and return indices of the first k neighbors\r\n",
    "        k_idxs = np.argsort(distances, axis=-1)[:, :k]\r\n",
    "        print(f\"{k_idxs.shape = }\")\r\n",
    "        # Extract the labels of the k nearest neighbor training samples\r\n",
    "        k_neighbor_labels = self.y_train[k_idxs]\r\n",
    "        print(f\"{k_neighbor_labels.shape = }\")\r\n",
    "        print(f\"{k_neighbor_labels[0] = }\")\r\n",
    "        # # return the most common class label\r\n",
    "        most_commons = [Counter(x).most_common(1)[0][0]\r\n",
    "                        for x in k_neighbor_labels]\r\n",
    "        most_commons = np.array(most_commons)\r\n",
    "        print(f\"{most_commons.shape = }\")\r\n",
    "\r\n",
    "        # print(f\"{np.array(most_commons).shape = }\")\r\n",
    "        return most_commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (120, 4)\n",
      "y_train.shape = (120,)\n",
      "X_test.shape = (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Imports\r\n",
    "from matplotlib.colors import ListedColormap\r\n",
    "from sklearn import datasets\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "cmap = ListedColormap([\"#FF0000\", \"#00FF00\", \"#0000FF\"])\r\n",
    "\r\n",
    "def accuracy(y_true, y_pred):\r\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true) * 100\r\n",
    "    return accuracy\r\n",
    "\r\n",
    "iris = datasets.load_iris()\r\n",
    "X, y = iris.data, iris.target\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, test_size=0.2, random_state=42\r\n",
    ")\r\n",
    "print(f\"{X_train.shape = }\")\r\n",
    "print(f\"{y_train.shape = }\")\r\n",
    "print(f\"{X_test.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\r\n",
    "clf = KNN(k=k)\r\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distances.shape = (30, 120)\n",
      "k_idxs.shape = (30, 3)\n",
      "k_neighbor_labels.shape = (30, 3)\n",
      "k_neighbor_labels[0] = array([1, 1, 1])\n",
      "most_commons.shape = (30,)\n",
      "Time elapsed for inference: 0.0015 seconds\n",
      "KNN classification accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\r\n",
    "predictions = clf.predict(X_test)\r\n",
    "total_inf_time = time.perf_counter() - start_time\r\n",
    "print(f\"Time elapsed for inference: {total_inf_time:.4f} seconds\")\r\n",
    "print(f\"KNN classification accuracy: {accuracy(y_test, predictions):.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}